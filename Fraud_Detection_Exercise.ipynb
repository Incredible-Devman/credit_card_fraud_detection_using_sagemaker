{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Credit Card Fraud\n",
    "\n",
    "In this section, we'll look at a credit card fraud detection dataset, and build a binary classification model that can identify transactions as either fraudulent or valid, based on provided, *historical* data. In a [2016 study](https://nilsonreport.com/upload/content_promo/The_Nilson_Report_10-17-2016.pdf), it was estimated that credit card fraud was responsible for over 20 billion dollars in loss, worldwide. Accurately detecting cases of fraud is an ongoing area of research.\n",
    "\n",
    "\n",
    "### Labeled Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The payment fraud data set (Dal Pozzolo et al. 2015) was downloaded from [Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud/data). This has features and labels for thousands of credit card transactions, each of which is labeled as fraudulent or valid. In this notebook, we'd like to train a model based on the features of these transactions so that we can predict risky or fraudulent transactions in the future.\n",
    "\n",
    "### Binary Classification\n",
    "\n",
    "Since we have true labels to aim for, we'll take a **supervised learning** approach and train a binary classifier to sort data into one of our two transaction classes: fraudulent or valid.  We'll train a model on training data and see how well it generalizes on some test data.\n",
    "\n",
    "The notebook will be broken down into a few steps:\n",
    "* Loading and exploring the data\n",
    "* Splitting the data into train/test sets\n",
    "* Defining and training a LinearLearner, binary classifier\n",
    "* Making improvements on the model\n",
    "* Evaluating and comparing model test performance\n",
    "\n",
    "### Making Improvements\n",
    "\n",
    "A lot of this notebook will focus on making improvements, as discussed in [this SageMaker blog post](https://aws.amazon.com/blogs/machine-learning/train-faster-more-flexible-models-with-amazon-sagemaker-linear-learner/). Specifically, we'll address techniques for:\n",
    "\n",
    "1. **Tuning a model's hyperparameters** and aiming for a specific metric, such as high recall or precision.\n",
    "2. **Managing class imbalance**, which is when we have many more training examples in one class than another (in this case, many more valid transactions than fraudulent).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the usual resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm storing my **SageMaker variables** in the next cell:\n",
    "* sagemaker_session: The SageMaker session we'll use for training models.\n",
    "* bucket: The name of the default S3 bucket that we'll use for data storage.\n",
    "* role: The IAM role that defines our data and model permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker session, role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# S3 bucket name\n",
    "bucket = sagemaker_session.default_bucket()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Exploring the Data\n",
    "\n",
    "Next, I am loading the data and unzipping the data in the file `creditcardfraud.zip`. This directory will hold one csv file of all the transaction data, `creditcard.csv`.\n",
    "\n",
    "As in previous notebooks, it's important to look at the distribution of data since this will inform how we develop a fraud detection model. We'll want to know: How many data points we have to work with, the number and type of features, and finally, the distribution of data over the classes (valid or fraudulent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-15 08:01:20--  https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c534768_creditcardfraud/creditcardfraud.zip\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.233.109\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.233.109|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 69155632 (66M) [application/zip]\n",
      "Saving to: ‘creditcardfraud.zip’\n",
      "\n",
      "creditcardfraud.zip 100%[===================>]  65.95M  9.82MB/s    in 6.5s    \n",
      "\n",
      "2020-03-15 08:01:27 (10.2 MB/s) - ‘creditcardfraud.zip’ saved [69155632/69155632]\n",
      "\n",
      "Archive:  creditcardfraud.zip\n",
      "  inflating: creditcard.csv          \n"
     ]
    }
   ],
   "source": [
    "# only have to run once\n",
    "!wget https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c534768_creditcardfraud/creditcardfraud.zip\n",
    "!unzip creditcardfraud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (rows, cols):  (284807, 31)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the csv file\n",
    "local_data = 'creditcard.csv'\n",
    "\n",
    "# print out some data\n",
    "transaction_df = pd.read_csv(local_data)\n",
    "print('Data shape (rows, cols): ', transaction_df.shape)\n",
    "print()\n",
    "transaction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Calculate the percentage of fraudulent data\n",
    "\n",
    "Take a look at the distribution of this transaction data over the classes, valid and fraudulent. \n",
    "\n",
    "Complete the function `fraudulent_percentage`, below. Count up the number of data points in each class and calculate the *percentage* of the data points that are fraudulent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the fraction of data points that are fraudulent\n",
    "def fraudulent_percentage(transaction_df):\n",
    "    '''Calculate the fraction of all data points that have a 'Class' label of 1; fraudulent.\n",
    "       :param transaction_df: Dataframe of all transaction data points; has a column 'Class'\n",
    "       :return: A fractional percentage of fraudulent data points/all points\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    return transaction_df[transaction_df['Class']==1].shape[0]/transaction_df.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test out your code by calling your function and printing the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraudulent percentage =  0.001727485630620034\n",
      "Total # of fraudulent pts:  492.0\n",
      "Out of (total) pts:  284807\n"
     ]
    }
   ],
   "source": [
    "# call the function to calculate the fraud percentage\n",
    "fraud_percentage = fraudulent_percentage(transaction_df)\n",
    "\n",
    "print('Fraudulent percentage = ', fraud_percentage)\n",
    "print('Total # of fraudulent pts: ', fraud_percentage*transaction_df.shape[0])\n",
    "print('Out of (total) pts: ', transaction_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Split into train/test datasets\n",
    "\n",
    "In this example, we'll want to evaluate the performance of a fraud classifier; training it on some training data and testing it on *test data* that it did not see during the training process. So, we'll need to split the data into separate training and test sets.\n",
    "\n",
    "Complete the `train_test_split` function, below. This function should:\n",
    "* Shuffle the transaction data, randomly\n",
    "* Split it into two sets according to the parameter `train_frac`\n",
    "* Get train/test features and labels\n",
    "* Return the tuples: (train_features, train_labels), (test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/test\n",
    "def train_test_split(transaction_df, test_size=0.3, seed=1):\n",
    "    '''Shuffle the data and randomly split into train and test sets;\n",
    "       separate the class labels (the column in transaction_df) from the features.\n",
    "       :param df: Dataframe of all credit card transaction data\n",
    "       :param train_frac: The decimal fraction of data that should be training data\n",
    "       :param seed: Random seed for shuffling and reproducibility, default = 1\n",
    "       :return: Two tuples (in order): (train_features, train_labels), (test_features, test_labels)\n",
    "       '''\n",
    "    matrix_df = transaction_df.values\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(matrix_df)\n",
    "\n",
    "    train_size = int(len(matrix_df) * (1 - test_size))\n",
    "    train_features = matrix_df[:train_size, :-1]\n",
    "    train_labels = matrix_df[:train_size, -1]\n",
    "    test_features = matrix_df[train_size:, :-1]\n",
    "    test_labels = matrix_df[train_size:, -1]\n",
    "    \n",
    "    return (train_features, train_labels), (test_features, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Cell\n",
    "\n",
    "In the cells below, I'm creating the train/test data and checking to see that result makes sense. The tests below test that the above function splits the data into the expected number of points and that the labels are indeed, class labels (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# get train/test data\n",
    "(train_features, train_labels), (test_features, test_labels) = train_test_split(transaction_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data pts:  199364\n",
      "Test data pts:  85443\n",
      "\n",
      "First item: \n",
      " [ 1.19907000e+05 -6.11711999e-01 -7.69705324e-01 -1.49759145e-01\n",
      " -2.24876503e-01  2.02857736e+00 -2.01988711e+00  2.92491387e-01\n",
      " -5.23020325e-01  3.58468461e-01  7.00499612e-02 -8.54022784e-01\n",
      "  5.47347360e-01  6.16448382e-01 -1.01785018e-01 -6.08491804e-01\n",
      " -2.88559430e-01 -6.06199260e-01 -9.00745518e-01 -2.01311157e-01\n",
      " -1.96039343e-01 -7.52077614e-02  4.55360454e-02  3.80739375e-01\n",
      "  2.34403159e-02 -2.22068576e+00 -2.01145578e-01  6.65013699e-02\n",
      "  2.21179560e-01  1.79000000e+00]\n",
      "Label:  0.0\n",
      "\n",
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "# manual test\n",
    "\n",
    "# for a split of 0.7:0.3 there should be ~2.33x as many training as test pts\n",
    "print('Training data pts: ', len(train_features))\n",
    "print('Test data pts: ', len(test_features))\n",
    "print()\n",
    "\n",
    "# take a look at first item and see that it aligns with first row of data\n",
    "print('First item: \\n', train_features[0])\n",
    "print('Label: ', train_labels[0])\n",
    "print()\n",
    "\n",
    "# test split\n",
    "assert len(train_features) > 2.333*len(test_features), \\\n",
    "        'Unexpected number of train/test points for a train_frac=0.7'\n",
    "# test labels\n",
    "assert np.all(train_labels)== 0 or np.all(train_labels)== 1, \\\n",
    "        'Train labels should be 0s or 1s.'\n",
    "assert np.all(test_labels)== 0 or np.all(test_labels)== 1, \\\n",
    "        'Test labels should be 0s or 1s.'\n",
    "print('Tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Modeling\n",
    "\n",
    "Now that you've uploaded your training data, it's time to define and train a model!\n",
    "\n",
    "In this notebook, you'll define and train the SageMaker, built-in algorithm, [LinearLearner](https://sagemaker.readthedocs.io/en/stable/linear_learner.html). \n",
    "\n",
    "A LinearLearner has two main applications:\n",
    "1. For regression tasks in which a linear line is fit to some data points, and you want to produce a predicted output value given some data point (example: predicting house prices given square area).\n",
    "2. For binary classification, in which a line is separating two classes of data and effectively outputs labels; either 1 for data that falls above the line or 0 for points that fall on or below the line.\n",
    "\n",
    "<img src='notebook_ims/linear_separator.png' width=50% />\n",
    "\n",
    "In this case, we'll be using it for case 2, and we'll train it to separate data into our two classes: valid or fraudulent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Create a LinearLearner Estimator\n",
    "\n",
    "You've had some practice instantiating built-in models in SageMaker. All estimators require some constructor arguments to be passed in. See if you can complete this task, instantiating a LinearLearner estimator, using only the [LinearLearner documentation](https://sagemaker.readthedocs.io/en/stable/linear_learner.html) as a resource. This takes in a lot of arguments, but not all are required. My suggestion is to start with a simple model, utilizing default values where applicable. Later, we will discuss some specific hyperparameters and their use cases.\n",
    "\n",
    "#### Instance Types\n",
    "\n",
    "It is suggested that you use instances that are available in the free tier of usage: `'ml.c4.xlarge'` for training and `'ml.t2.medium'` for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import LinearLearner\n",
    "from sagemaker import LinearLearner\n",
    "\n",
    "prefix='creditcardfraud'\n",
    "output_path='s3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# instantiate LinearLearner\n",
    "linlearn = LinearLearner(role=role,\n",
    "                         train_instance_count=1,\n",
    "                         train_instance_type='ml.c4.xlarge',\n",
    "                         predictor_type='binary_classifier',\n",
    "                         output_path=output_path,\n",
    "                         sagemaker_session=sagemaker_session,\n",
    "                         epochs=15\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Convert data into a RecordSet format\n",
    "\n",
    "Next, prepare the data for a built-in model by converting the train features and labels into numpy array's of float values. Then you can use the [record_set function](https://sagemaker.readthedocs.io/en/stable/linear_learner.html#sagemaker.LinearLearner.record_set) to format the data as a RecordSet and prepare it for training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RecordSet of training data\n",
    "\n",
    "train_x_np = train_features.astype('float32')\n",
    "train_y_np = train_labels.astype('float32')\n",
    "\n",
    "formatted_train_data = linlearn.record_set(train_x_np, labels=train_y_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Train the Estimator\n",
    "\n",
    "After instantiating your estimator, train it with a call to `.fit()`, passing in the formatted training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# train the estimator on formatted training data\n",
    "linlearn.fit(formatted_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Deploy the trained model\n",
    "\n",
    "Deploy your model to create a predictor. We'll use this to make predictions on our test data and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# deploy and create a predictor\n",
    "linear_predictor = linlearn.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Evaluating Your Model\n",
    "\n",
    "Once your model is deployed, you can see how it performs when applied to the test data.\n",
    "\n",
    "According to the deployed [predictor documentation](https://sagemaker.readthedocs.io/en/stable/linear_learner.html#sagemaker.LinearLearnerPredictor), this predictor expects an `ndarray` of input features and returns a list of Records.\n",
    "> \"The prediction is stored in the \"predicted_label\" key of the `Record.label` field.\"\n",
    "\n",
    "Let's first test our model on just one test point, to see the resulting list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[label {\n",
      "  key: \"predicted_label\"\n",
      "  value {\n",
      "    float32_tensor {\n",
      "      values: 0.0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "label {\n",
      "  key: \"score\"\n",
      "  value {\n",
      "    float32_tensor {\n",
      "      values: 0.001805478474125266\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# test one prediction\n",
    "test_x_np = test_features.astype('float32')\n",
    "result = linear_predictor.predict(test_x_np[0])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for evaluation\n",
    "\n",
    "\n",
    "The provided function below, takes in a deployed predictor, some test features and labels, and returns a dictionary of metrics; calculating false negatives and positives as well as recall, precision, and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to evaluate the endpoint on test data\n",
    "# returns a variety of model metrics\n",
    "def evaluate(predictor, test_features, test_labels, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  \n",
    "    Return binary classification metrics.\n",
    "    :param predictor: A prediction endpoint\n",
    "    :param test_features: Test features\n",
    "    :param test_labels: Class labels for test data\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We have a lot of test data, so we'll split it into batches of 100\n",
    "    # split the test data set into batches and evaluate using prediction endpoint    \n",
    "    prediction_batches = [predictor.predict(batch) for batch in np.array_split(test_features, 100)]\n",
    "    \n",
    "    # LinearLearner produces a `predicted_label` for each data point in a batch\n",
    "    # get the 'predicted_label' for every point in a batch\n",
    "    test_preds = np.concatenate([np.array([x.label['predicted_label'].float32_tensor.values[0] for x in batch]) \n",
    "                                 for batch in prediction_batches])\n",
    "    \n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    # printing a table of metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actual (row)'], colnames=['prediction (col)']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print()\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, \n",
    "            'Precision': precision, 'Recall': recall, 'Accuracy': accuracy}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results\n",
    "\n",
    "The cell below runs the `evaluate` function. \n",
    "\n",
    "The code assumes that you have a defined `predictor` and `test_features` and `test_labels` from previously-run cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for simple, LinearLearner.\n",
      "\n",
      "prediction (col)    0.0  1.0\n",
      "actual (row)                \n",
      "0.0               85269   33\n",
      "1.0                  32  109\n",
      "\n",
      "Recall:     0.773\n",
      "Precision:  0.768\n",
      "Accuracy:   0.999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Metrics for simple, LinearLearner.\\n')\n",
    "\n",
    "# get metrics for linear predictor\n",
    "metrics = evaluate(linear_predictor, \n",
    "                   test_features.astype('float32'), \n",
    "                   test_labels, \n",
    "                   verbose=True) # verbose means we'll print out the metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Endpoint\n",
    "\n",
    "I've added a convenience function to delete prediction endpoints after we're done with them. And if you're done evaluating the model, you should delete your model endpoint!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletes a precictor.endpoint\n",
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName=predictor.endpoint)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted linear-learner-2020-03-15-09-40-34-294\n"
     ]
    }
   ],
   "source": [
    "# delete the predictor endpoint \n",
    "delete_endpoint(linear_predictor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "None."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
